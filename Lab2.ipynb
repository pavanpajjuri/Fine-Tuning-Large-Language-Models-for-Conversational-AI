{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNDJN/2XKkV7subfWhTbHzV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"580028722f3a4351ba4c4ef9454528e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6586b5d8fab48c18af42590ac836d45","IPY_MODEL_5cc2925177b04ac0ab9a8227fcd3d41d","IPY_MODEL_4314369e94c747d7b0128a8c913c9982"],"layout":"IPY_MODEL_62cb8cf9851549e193b960dafbdd86e2"}},"a6586b5d8fab48c18af42590ac836d45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cbbbe6341b04d5296bd767e80732e07","placeholder":"​","style":"IPY_MODEL_53400b8844c240db80cfd9a75e9a2160","value":"Map: 100%"}},"5cc2925177b04ac0ab9a8227fcd3d41d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b686c9a51b7d45e283d9f432acb48ec7","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39a8f73c75aa41bba33e983fdfcb1f2c","value":500}},"4314369e94c747d7b0128a8c913c9982":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_927e1628c63141dfb345ec3894e9ba36","placeholder":"​","style":"IPY_MODEL_d393221a20e045b1847c760a9745495f","value":" 500/500 [00:00&lt;00:00, 831.00 examples/s]"}},"62cb8cf9851549e193b960dafbdd86e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cbbbe6341b04d5296bd767e80732e07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53400b8844c240db80cfd9a75e9a2160":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b686c9a51b7d45e283d9f432acb48ec7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39a8f73c75aa41bba33e983fdfcb1f2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"927e1628c63141dfb345ec3894e9ba36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d393221a20e045b1847c760a9745495f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"461af978971940759b766976ef044d39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07c8330776584271912030ff1a3d4aa0","IPY_MODEL_94d0cd6d5d714062b34fa6008ceaf302","IPY_MODEL_8155b0803c9a4ff2a541bf30f4437524"],"layout":"IPY_MODEL_5071899c2342400c83377ef483ecf5e6"}},"07c8330776584271912030ff1a3d4aa0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77002f7cd7fa47eab5b0f2bd53091124","placeholder":"​","style":"IPY_MODEL_d5ad57e8bfba46e69b7b70358e7efdc2","value":"Filter: 100%"}},"94d0cd6d5d714062b34fa6008ceaf302":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4504e4065d849de8dfe9960ce5fde59","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1a1a5d655004763b23f38f141b6dd2c","value":500}},"8155b0803c9a4ff2a541bf30f4437524":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed9d24a24b5a41458f7958fe2af5dd14","placeholder":"​","style":"IPY_MODEL_16e88b788c4b4ddfaae0fe15d5d1cbc7","value":" 500/500 [00:00&lt;00:00, 1779.92 examples/s]"}},"5071899c2342400c83377ef483ecf5e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77002f7cd7fa47eab5b0f2bd53091124":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5ad57e8bfba46e69b7b70358e7efdc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4504e4065d849de8dfe9960ce5fde59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1a1a5d655004763b23f38f141b6dd2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed9d24a24b5a41458f7958fe2af5dd14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16e88b788c4b4ddfaae0fe15d5d1cbc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b11f002df4374dd99ae4620a65a74572":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f65620768424877b209d18fcfc7b245","IPY_MODEL_4d53c86e40c24597b9c6d744c8e5921a","IPY_MODEL_3e956b33c95d42e89e0378562e49d01d"],"layout":"IPY_MODEL_61ce255e4a104d64b9f3048edf53c6d7"}},"0f65620768424877b209d18fcfc7b245":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9e8274eb3934e9394eb849c51aa1d20","placeholder":"​","style":"IPY_MODEL_5169bb96adf84c499fcf4193efbfcb48","value":"Downloading builder script: 100%"}},"4d53c86e40c24597b9c6d744c8e5921a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e14b798727654622a6d41798cbf877a7","max":6270,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32ffd88490004e0e9dd1266316021793","value":6270}},"3e956b33c95d42e89e0378562e49d01d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33801488e9e94b1aa4aa6d1b342fc73f","placeholder":"​","style":"IPY_MODEL_18908a0b59394288bdd38d70894b9524","value":" 6.27k/6.27k [00:00&lt;00:00, 101kB/s]"}},"61ce255e4a104d64b9f3048edf53c6d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9e8274eb3934e9394eb849c51aa1d20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5169bb96adf84c499fcf4193efbfcb48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e14b798727654622a6d41798cbf877a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32ffd88490004e0e9dd1266316021793":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33801488e9e94b1aa4aa6d1b342fc73f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18908a0b59394288bdd38d70894b9524":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fMbAetbg9pIh","executionInfo":{"status":"ok","timestamp":1728254210460,"user_tz":240,"elapsed":187208,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"a2447252-8f28-4964-f10e-9a25876ee2db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n","Collecting pip\n","  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n","Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n","Installing collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","Successfully installed pip-24.2\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 1.13.1 which is incompatible.\n","torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mCollecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Collecting datasets>=2.0.0 (from evaluate)\n","  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n","Collecting xxhash (from evaluate)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.8)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","Collecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","Installing collected packages: xxhash, dill, multiprocess, datasets, evaluate\n","Successfully installed datasets-3.0.1 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 xxhash-3.5.0\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=b8fb927a91fee8360afdb28547e601dfc8ff3ba303538b3d09d4b07f09abff8f\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m125.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["%pip install --upgrade pip\n","%pip install --disable-pip-version-check \\\n","    torch==1.13.1 \\\n","    torchdata==0.5.1 --quiet\n","%pip install evaluate\n","%pip install rouge_score\n","%pip install \\\n","    transformers==4.27.2 \\\n","    datasets==2.11.0  --quiet"]},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, Trainer, TrainingArguments\n","import torch\n","import time\n","import pandas as pd\n","import numpy as np\n","import evaluate"],"metadata":{"id":"Id8wq5Ce93cL","executionInfo":{"status":"ok","timestamp":1728254546490,"user_tz":240,"elapsed":13834,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# !pip install --upgrade datasets\n","# !pip install awscli\n","# !pip install peft"],"metadata":{"id":"W39G1-VE_tDW","executionInfo":{"status":"ok","timestamp":1728254285471,"user_tz":240,"elapsed":4,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["huggingface_dataset_name = 'knkarthick/dialogsum'\n","dataset = load_dataset(huggingface_dataset_name)\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gws1z7QV_O44","executionInfo":{"status":"ok","timestamp":1728254550374,"user_tz":240,"elapsed":1216,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"3c7a41c4-d041-4dcf-fc66-7e620dd55e41"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'summary', 'topic'],\n","        num_rows: 12460\n","    })\n","    validation: Dataset({\n","        features: ['id', 'dialogue', 'summary', 'topic'],\n","        num_rows: 500\n","    })\n","    test: Dataset({\n","        features: ['id', 'dialogue', 'summary', 'topic'],\n","        num_rows: 1500\n","    })\n","})"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["model_name = 'google/flan-t5-base'\n","\n","original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name,torch_dtype = torch.bfloat16)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PauJ1WQn_oqo","executionInfo":{"status":"ok","timestamp":1728254560274,"user_tz":240,"elapsed":6999,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"3de0f957-7953-44b7-d273-4ea2e09ec30f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def print_number_of_trainable_model_parameters(model):\n","  all_model_params = 0\n","  trainable_model_params = 0\n","\n","  for _, param in model.named_parameters():\n","    all_model_params += param.numel()\n","    if param.requires_grad:\n","      trainable_model_params += param.numel()\n","\n","  return f\"trainable model parameters : {trainable_model_params}\\nall model parameter : {all_model_params}\\npercentage of trainable model parameters : {trainable_model_params/all_model_params*100 :.2f}%\"\n","\n","\n","print(print_number_of_trainable_model_parameters(original_model))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZWS0wLH_B2ft","executionInfo":{"status":"ok","timestamp":1728254563205,"user_tz":240,"elapsed":167,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"ad45c29f-6393-41ca-a5c4-eb9fd2061fea"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable model parameters : 247577856\n","all model parameter : 247577856\n","percentage of trainable model parameters : 100.00%\n"]}]},{"cell_type":"code","source":["index = 200\n","\n","dialogue = dataset['test'][index]['dialogue']\n","summary = dataset['test'][index]['summary']\n","\n","prompt = f\"\"\"\n","Summarize the following conversation :\n","\n","{dialogue}\n","\n","Summary :\n","\"\"\"\n","\n","inputs = tokenizer(prompt, return_tensors = 'pt')\n","output = tokenizer.decode(\n","                      original_model.generate(inputs['input_ids'],\n","                                              max_new_tokens = 200)[0],\n","                      skip_special_tokens = True\n",")\n","\n","dash_line = '-'.join('' for x in range(100))\n","print(dash_line)\n","print(f'INPUT PROMPT:\\n{prompt}')\n","print(dash_line)\n","print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n","print(dash_line)\n","print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPXRKBJ4Eub-","executionInfo":{"status":"ok","timestamp":1728254613734,"user_tz":240,"elapsed":49845,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"40596a1a-0cf3-4e33-ea95-8572bdd1f836"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------------------------\n","INPUT PROMPT:\n","\n","Summarize the following conversation :\n","\n","#Person1#: Have you considered upgrading your system?\n","#Person2#: Yes, but I'm not sure what exactly I would need.\n","#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n","#Person2#: That would be a definite bonus.\n","#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n","#Person2#: How can we do that?\n","#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n","#Person2#: No.\n","#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n","#Person2#: That sounds great. Thanks.\n","\n","Summary :\n","\n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n","---------------------------------------------------------------------------------------------------\n","MODEL GENERATION - ZERO SHOT:\n","#Person1#: You'd probably want to upgrade your computer. #Person2#: You could also upgrade your hardware.\n","\n"]}]},{"cell_type":"code","source":["def tokenize_function(example):\n","  start_prompt = 'Summarize the following conversation. \\n\\n'\n","  end_prompt = '\\n\\nSummary: '\n","  prompt = [start_prompt + dialogue + end_prompt for dialogue in example['dialogue']]\n","  example['input_ids'] = tokenizer(prompt, padding = 'max_length', truncation = True ,return_tensors = 'pt').input_ids\n","  example['labels'] = tokenizer(example['summary'], padding = 'max_length', truncation = True ,return_tensors = 'pt').input_ids\n","\n","  return example\n","\n","tokenized_datasets = dataset.map(tokenize_function, batched = True)\n","tokenized_datasets = tokenized_datasets.remove_columns(['id','topic','dialogue','summary'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["580028722f3a4351ba4c4ef9454528e7","a6586b5d8fab48c18af42590ac836d45","5cc2925177b04ac0ab9a8227fcd3d41d","4314369e94c747d7b0128a8c913c9982","62cb8cf9851549e193b960dafbdd86e2","3cbbbe6341b04d5296bd767e80732e07","53400b8844c240db80cfd9a75e9a2160","b686c9a51b7d45e283d9f432acb48ec7","39a8f73c75aa41bba33e983fdfcb1f2c","927e1628c63141dfb345ec3894e9ba36","d393221a20e045b1847c760a9745495f"]},"id":"JRAojBtoIEFP","executionInfo":{"status":"ok","timestamp":1728254614445,"user_tz":240,"elapsed":718,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"00fd0b6d-1b3f-4a52-94cb-da3d674a64fa"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"580028722f3a4351ba4c4ef9454528e7"}},"metadata":{}}]},{"cell_type":"code","source":["tokenized_datasets = tokenized_datasets.filter(lambda example,index : index%100 == 0, with_indices = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["461af978971940759b766976ef044d39","07c8330776584271912030ff1a3d4aa0","94d0cd6d5d714062b34fa6008ceaf302","8155b0803c9a4ff2a541bf30f4437524","5071899c2342400c83377ef483ecf5e6","77002f7cd7fa47eab5b0f2bd53091124","d5ad57e8bfba46e69b7b70358e7efdc2","e4504e4065d849de8dfe9960ce5fde59","c1a1a5d655004763b23f38f141b6dd2c","ed9d24a24b5a41458f7958fe2af5dd14","16e88b788c4b4ddfaae0fe15d5d1cbc7"]},"id":"LOln9LB_bWL7","executionInfo":{"status":"ok","timestamp":1728254614598,"user_tz":240,"elapsed":158,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"b4f24b36-4ef8-4e8a-a2ab-2f7ea843fa96"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"461af978971940759b766976ef044d39"}},"metadata":{}}]},{"cell_type":"code","source":["print(f\"Shapes of the datasets:\")\n","print(f\"Training: {tokenized_datasets['train'].shape}\")\n","print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n","print(f\"Test: {tokenized_datasets['test'].shape}\")\n","\n","print(tokenized_datasets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbSt6KzKb4ar","executionInfo":{"status":"ok","timestamp":1728254614761,"user_tz":240,"elapsed":164,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"3323691b-8943-4809-8253-662566fc39a5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Shapes of the datasets:\n","Training: (125, 2)\n","Validation: (5, 2)\n","Test: (15, 2)\n","DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'labels'],\n","        num_rows: 125\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'labels'],\n","        num_rows: 5\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'labels'],\n","        num_rows: 15\n","    })\n","})\n"]}]},{"cell_type":"code","source":["# output_dir = f'./dialogue-summary-training-{str(int(time.time()))}'\n","\n","# training_args = TrainingArguments(\n","#     output_dir=output_dir,\n","#     learning_rate=1e-5,\n","#     num_train_epochs=1,\n","#     weight_decay=0.01,\n","#     logging_steps=1,\n","#     max_steps=1\n","# )\n","\n","# trainer = Trainer(\n","#     model=original_model,\n","#     args=training_args,\n","#     train_dataset=tokenized_datasets['train'],\n","#     eval_dataset=tokenized_datasets['validation']\n","# )"],"metadata":{"id":"bxOVVl8jh4SY","executionInfo":{"status":"ok","timestamp":1728254614761,"user_tz":240,"elapsed":3,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# trainer.train()\n"],"metadata":{"id":"lReLG1pAjjJq","executionInfo":{"status":"ok","timestamp":1728254614762,"user_tz":240,"elapsed":3,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!aws configure"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QO8LuDfqCNaQ","executionInfo":{"status":"ok","timestamp":1728254659116,"user_tz":240,"elapsed":44357,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"0aa0820a-f82f-4c3d-e30a-05d1e0c2a2aa"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["AWS Access Key ID [None]: AKIAS2VS4JARWX4ES65B\n","AWS Secret Access Key [None]: 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\n","Default region name [None]: us-east-2\n","Default output format [None]: json\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0eqQLMXuCXOC","executionInfo":{"status":"ok","timestamp":1728020565948,"user_tz":240,"elapsed":230883,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"808fecfe-3693-48f7-cf2d-220bb32688a2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["AWS Access Key ID [None]: AKIAS2VS4JARWX4ES65B\n","AWS Secret Access Key [None]: 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\n","Default region name [None]: us-east-2\n","Default output format [None]: json\n"]}]},{"cell_type":"markdown","source":["AWS Access Key ID [None]: AKIAS2VS4JARWX4ES65B\n","AWS Secret Access Key [None]: 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\n","Default region name [None]: us-east-2\n","Default output format [None]: json"],"metadata":{"id":"HgMFZwmi_qtl"}},{"cell_type":"code","source":[],"metadata":{"id":"51GlHA2kCdSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!aws s3 cp --recursive s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/ ./flan-dialogue-summary-checkpoint/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4_DFJyGjrol","executionInfo":{"status":"ok","timestamp":1728254701599,"user_tz":240,"elapsed":33700,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"a1060316-81aa-4796-a5f3-da69907d01cf"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Completed 627 Bytes/2.8 GiB (291 Bytes/s) with 8 file(s) remaining\rdownload: s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/scheduler.pt to flan-dialogue-summary-checkpoint/scheduler.pt\n","Completed 627 Bytes/2.8 GiB (291 Bytes/s) with 7 file(s) remaining\rCompleted 769 Bytes/2.8 GiB (355 Bytes/s) with 7 file(s) remaining\rdownload: s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/generation_config.json to flan-dialogue-summary-checkpoint/generation_config.json\n","download: s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/config.json to flan-dialogue-summary-checkpoint/config.json\n","download: s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/trainer_state.json to flan-dialogue-summary-checkpoint/trainer_state.json\n","download: s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/training_args.bin to flan-dialogue-summary-checkpoint/training_args.bin\n","download: s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/rng_state.pth to flan-dialogue-summary-checkpoint/rng_state.pth\n","download: s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/pytorch_model.bin to flan-dialogue-summary-checkpoint/pytorch_model.bin\n","download: s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/optimizer.pt to flan-dialogue-summary-checkpoint/optimizer.pt\n"]}]},{"cell_type":"code","source":["!ls -alh ./flan-dialogue-summary-checkpoint/pytorch_model.bin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qaJ4s8CRof5Y","executionInfo":{"status":"ok","timestamp":1728254701776,"user_tz":240,"elapsed":178,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"80f0f642-400b-449e-a933-41e15508223a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["-rw-r--r-- 1 root root 945M May 15  2023 ./flan-dialogue-summary-checkpoint/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["instruct_model = AutoModelForSeq2SeqLM.from_pretrained(\"./flan-dialogue-summary-checkpoint\", torch_dtype=torch.bfloat16)"],"metadata":{"id":"v66byGZJD3_1","executionInfo":{"status":"ok","timestamp":1728254727124,"user_tz":240,"elapsed":7604,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["index = 200\n","\n","dialogue = dataset['test'][index]['dialogue']\n","summary = dataset['test'][index]['summary']\n","\n","prompt = f\"\"\"\n","Summarize the following conversation :\n","\n","{dialogue}\n","\n","Summary :\n","\"\"\"\n","\n","generate_config = GenerationConfig(max_new_tokens = 200, num_beams = 1)\n","input_ids = tokenizer(prompt, return_tensors = 'pt').input_ids\n","\n","original_model_output = tokenizer.decode(\n","                      original_model.generate(input_ids,\n","                                              generation_config = generate_config)[0],\n","                      skip_special_tokens = True\n",")\n","\n","instruct_model_output = tokenizer.decode(\n","                      instruct_model.generate(input_ids,\n","                                              generation_config = generate_config)[0],\n","                      skip_special_tokens = True\n",")\n","\n","dash_line = '-'.join('' for x in range(100))\n","print(dash_line)\n","print(f'INPUT PROMPT:\\n{prompt}')\n","print(dash_line)\n","print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n","print(dash_line)\n","print(f'ORIGINAL MODEL:\\n{original_model_output}\\n')\n","print(dash_line)\n","print(f'INSTRUCT MODEL:\\n{instruct_model_output}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCfikmn0D7UU","executionInfo":{"status":"ok","timestamp":1728022068160,"user_tz":240,"elapsed":102158,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"14692b7e-0009-4d25-fbe1-c9e665fbd520"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------------------------\n","INPUT PROMPT:\n","\n","Summarize the following conversation :\n","\n","#Person1#: Have you considered upgrading your system?\n","#Person2#: Yes, but I'm not sure what exactly I would need.\n","#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n","#Person2#: That would be a definite bonus.\n","#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n","#Person2#: How can we do that?\n","#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n","#Person2#: No.\n","#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n","#Person2#: That sounds great. Thanks.\n","\n","Summary :\n","\n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n","---------------------------------------------------------------------------------------------------\n","ORIGINAL MODEL:\n","#Person1#: You'd probably want to upgrade your computer. #Person2#: You could also upgrade your hardware.\n","\n","---------------------------------------------------------------------------------------------------\n","INSTRUCT MODEL:\n","#Person1# suggests #Person2# upgrading the system, hardware, and CD-ROM drive to make up for the outdated system. #Person2# thinks it sounds great.\n","\n"]}]},{"cell_type":"code","source":["rouge = evaluate.load('rouge')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["b11f002df4374dd99ae4620a65a74572","0f65620768424877b209d18fcfc7b245","4d53c86e40c24597b9c6d744c8e5921a","3e956b33c95d42e89e0378562e49d01d","61ce255e4a104d64b9f3048edf53c6d7","b9e8274eb3934e9394eb849c51aa1d20","5169bb96adf84c499fcf4193efbfcb48","e14b798727654622a6d41798cbf877a7","32ffd88490004e0e9dd1266316021793","33801488e9e94b1aa4aa6d1b342fc73f","18908a0b59394288bdd38d70894b9524"]},"id":"wWdHGanWJip3","executionInfo":{"status":"ok","timestamp":1728254759726,"user_tz":240,"elapsed":1504,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"f2a93a42-6753-4024-f4c9-97c7a0b65736"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b11f002df4374dd99ae4620a65a74572"}},"metadata":{}}]},{"cell_type":"code","source":["dialogues = dataset['test'][8:10]['dialogue']\n","summaries = dataset['test'][8:10]['summary']\n","generate_config = GenerationConfig(max_new_tokens = 200, num_beams = 1)\n","\n","original_model_summaries = []\n","instruct_model_summaries = []\n","\n","for _,dialogue in enumerate(dialogues):\n","  prompt = f\"\"\"\n","  Summarize the following conversation :\n","\n","  {dialogue}\n","\n","  Summary :\n","  \"\"\"\n","\n","  input_ids = tokenizer(prompt, return_tensors = 'pt').input_ids\n","  original_model_output = tokenizer.decode(\n","                        original_model.generate(input_ids,\n","                                                generation_config = generate_config)[0],\n","                        skip_special_tokens = True\n","  )\n","\n","  instruct_model_output = tokenizer.decode(\n","                        instruct_model.generate(input_ids,\n","                                                generation_config = generate_config)[0],\n","                        skip_special_tokens = True\n","  )\n","\n","  original_model_summaries.append(original_model_output)\n","  instruct_model_summaries.append(instruct_model_output)\n","\n","zipped_summaries = list(zip(summaries,original_model_summaries,instruct_model_summaries))\n","df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries','original_model_summaries','instruct_model_summaries'])\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"id":"szMxs4aXJnML","executionInfo":{"status":"ok","timestamp":1728254953853,"user_tz":240,"elapsed":184014,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"de87ed02-b1e7-4139-d645-1ddf98610bd4"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                            human_baseline_summaries  \\\n","0  #Person1# and Kate talk about the divorce betw...   \n","1  #Person1# and Brian are at the birthday party ...   \n","\n","               original_model_summaries  \\\n","0  Masha and Hero are getting divorced.   \n","1        Brian's birthday is coming up.   \n","\n","                            instruct_model_summaries  \n","0  Masha and Hero are getting divorced. Kate can'...  \n","1  Brian's birthday is coming. #Person1# invites ...  "],"text/html":["\n","  <div id=\"df-8c1db155-d347-4c6d-8e0d-bd42966d8c4f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>human_baseline_summaries</th>\n","      <th>original_model_summaries</th>\n","      <th>instruct_model_summaries</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>#Person1# and Kate talk about the divorce betw...</td>\n","      <td>Masha and Hero are getting divorced.</td>\n","      <td>Masha and Hero are getting divorced. Kate can'...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>#Person1# and Brian are at the birthday party ...</td>\n","      <td>Brian's birthday is coming up.</td>\n","      <td>Brian's birthday is coming. #Person1# invites ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c1db155-d347-4c6d-8e0d-bd42966d8c4f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8c1db155-d347-4c6d-8e0d-bd42966d8c4f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8c1db155-d347-4c6d-8e0d-bd42966d8c4f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f7fe1d80-cc42-4a5f-bf23-e34453493f0e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7fe1d80-cc42-4a5f-bf23-e34453493f0e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f7fe1d80-cc42-4a5f-bf23-e34453493f0e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_b5d2cd7e-2fac-45b2-bd33-73d65631b036\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_b5d2cd7e-2fac-45b2-bd33-73d65631b036 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"human_baseline_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"#Person1# and Brian are at the birthday party of Brian. Brian thinks #Person1# looks great and is popular.\",\n          \"#Person1# and Kate talk about the divorce between Masha and Hero. Kate feels surprised because she thought they are well matched\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Brian's birthday is coming up.\",\n          \"Masha and Hero are getting divorced.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruct_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Brian's birthday is coming. #Person1# invites Brian to have a dance and Brian compliments #Person1#'s looks. Brian thinks #Person1# looks great and invites #Person1# to have a drink together.\",\n          \"Masha and Hero are getting divorced. Kate can't believe it. #Person1# tells Kate they are having a separation for 2 months and filed for divorce. Kate thinks it's surprising and can't believe it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["original_model_scores = rouge.compute(\n","    predictions = original_model_summaries,\n","    references = summaries[0:len(original_model_summaries)],\n","    use_aggregator = True,\n","    use_stemmer = True\n",")\n","\n","instruct_model_scores = rouge.compute(\n","    predictions = instruct_model_summaries,\n","    references = summaries[0:len(instruct_model_summaries)],\n","    use_aggregator = True,\n","    use_stemmer = True\n",")\n","\n","print(f'ORIGINAL MODEL RESULTS :\\n{original_model_scores}')\n","print(f'INSTRUCT MODEL RESULTS :\\n{instruct_model_scores}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"heVx0NenJtzF","executionInfo":{"status":"ok","timestamp":1728255018873,"user_tz":240,"elapsed":633,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"3a476b4e-fa52-448a-d118-10d259eab5fd"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["ORIGINAL MODEL RESULTS :\n","{'rouge1': 0.3101851851851852, 'rouge2': 0.08000000000000002, 'rougeL': 0.27314814814814814, 'rougeLsum': 0.27314814814814814}\n","INSTRUCT MODEL RESULTS :\n","{'rouge1': 0.43788041532402433, 'rouge2': 0.18220502901353966, 'rougeL': 0.288936627282492, 'rougeLsum': 0.288936627282492}\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","results = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1mkRUGT5N4WFFOvysfGgCXo2ZYAZe8qVWWQIEtaCU5DQ/export?format=csv\")\n","results.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"vQiwGftAMzFB","executionInfo":{"status":"ok","timestamp":1728255021842,"user_tz":240,"elapsed":907,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"246d8f1e-861b-4997-8097-62226c88d4e9"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                           human_baseline_summaries  \\\n","0           0  Ms. Dawson helps #Person1# to write a memo to ...   \n","1           1  In order to prevent employees from wasting tim...   \n","2           2  Ms. Dawson takes a dictation for #Person1# abo...   \n","3           3  #Person2# arrives late because of traffic jam....   \n","4           4  #Person2# decides to follow #Person1#'s sugges...   \n","\n","                            original_model_summaries  \\\n","0  The memo is to be distributed to all employees...   \n","1  The memo is to be distributed to all employees...   \n","2  The memo is to be distributed to all employees...   \n","3  The traffic jam at the Carrefour intersection ...   \n","4  The traffic jam at the Carrefour intersection ...   \n","\n","                            instruct_model_summaries  \\\n","0  #Person1# asks Ms. Dawson to take a dictation ...   \n","1  #Person1# asks Ms. Dawson to take a dictation ...   \n","2  #Person1# asks Ms. Dawson to take a dictation ...   \n","3  #Person2# got stuck in traffic again. #Person1...   \n","4  #Person2# got stuck in traffic again. #Person1...   \n","\n","                                peft_model_summaries  \n","0  #Person1# asks Ms. Dawson to take a dictation ...  \n","1  #Person1# asks Ms. Dawson to take a dictation ...  \n","2  #Person1# asks Ms. Dawson to take a dictation ...  \n","3  #Person2# got stuck in traffic and got stuck i...  \n","4  #Person2# got stuck in traffic and got stuck i...  "],"text/html":["\n","  <div id=\"df-d398951e-4471-4bdf-a0f8-da5b07d56e53\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>human_baseline_summaries</th>\n","      <th>original_model_summaries</th>\n","      <th>instruct_model_summaries</th>\n","      <th>peft_model_summaries</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n","      <td>The memo is to be distributed to all employees...</td>\n","      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n","      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>In order to prevent employees from wasting tim...</td>\n","      <td>The memo is to be distributed to all employees...</td>\n","      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n","      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n","      <td>The memo is to be distributed to all employees...</td>\n","      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n","      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>#Person2# arrives late because of traffic jam....</td>\n","      <td>The traffic jam at the Carrefour intersection ...</td>\n","      <td>#Person2# got stuck in traffic again. #Person1...</td>\n","      <td>#Person2# got stuck in traffic and got stuck i...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n","      <td>The traffic jam at the Carrefour intersection ...</td>\n","      <td>#Person2# got stuck in traffic again. #Person1...</td>\n","      <td>#Person2# got stuck in traffic and got stuck i...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d398951e-4471-4bdf-a0f8-da5b07d56e53')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d398951e-4471-4bdf-a0f8-da5b07d56e53 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d398951e-4471-4bdf-a0f8-da5b07d56e53');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-041a6808-26c4-442a-b076-a029ad0ea57c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-041a6808-26c4-442a-b076-a029ad0ea57c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-041a6808-26c4-442a-b076-a029ad0ea57c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results","summary":"{\n  \"name\": \"results\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 433,\n        \"min\": 0,\n        \"max\": 1499,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          1116,\n          1368,\n          422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"human_baseline_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1487,\n        \"samples\": [\n          \"Paul will go to celebrate Thanksgiving Day with #Person1#'s family and he decides to take a bottle of wine as the gift after discussion with #Person1#.\",\n          \"Kathy thinks the countryside in the North Carolina Mountains is so noisy as birds come out at this period and #Person2# only hears those birds when #Person2# was in Atlanta\",\n          \"#Person1# and #Person2# are talking about the founding time and founder of the New York Times, the Washington Post, and the Los Angeles Times were founded.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 494,\n        \"samples\": [\n          \"#Person1#: Hello! I'm trying to take a bath, but there are too many buttons, would you tell me how to use them?\",\n          \"Mary is tired.\",\n          \"Then, you can go to China for sightseeing.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruct_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 496,\n        \"samples\": [\n          \"#Person2# tells #Person1# the shelf of best-sellers is all best-sellers. #Person1# asks #Person2# for some advice on books for killing time on the train.\",\n          \"Mary is tired because she goes to the personnel market every day. #Person1# suggests Mary apply for a job on the Internet and tells her how to apply for a job on the Internet. Mary will give it a try at once.\",\n          \"Laura is going to the gym. #Person1# tells Laura that women exercise for both health and to look good. Laura also talks about her regular exercise and sports. Laura invites #Person1# to join her at the gym.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"peft_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 498,\n        \"samples\": [\n          \"Kathy tells #Person1# the countryside is noisy because of the 17-year bird calls. #Person1# thinks it's terrible because the birds live in the trees and they don't have them in the city.\",\n          \"Mary is tired and wants to apply for a job on the Internet. #Person1# recommends applying online and send an application through email to the employer. Mary will try it at once.\",\n          \"Laura is going to the gym to stay in shape. Laura tells #Person1# she has to stay in shape because she wants to look good and exercise. Laura also tells #Person1# she has to go to the gym and play tennis with friends. Laura wants to join her at the gym someday but she's lazy about things like that.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["results.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHFRKM14Q6H4","executionInfo":{"status":"ok","timestamp":1728255028482,"user_tz":240,"elapsed":218,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"4fc2e8ef-9a67-4020-c400-c90de2600bea"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1500, 5)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["summaries = results.human_baseline_summaries.values\n","original_model_summaries = results.original_model_summaries.values\n","instruct_model_summaries = results.instruct_model_summaries.values\n","\n","\n","original_model_scores = rouge.compute(\n","    predictions = original_model_summaries,\n","    references = summaries[0:len(original_model_summaries)],\n","    use_aggregator = True,\n","    use_stemmer = True\n",")\n","\n","instruct_model_scores = rouge.compute(\n","    predictions = instruct_model_summaries,\n","    references = summaries[0:len(instruct_model_summaries)],\n","    use_aggregator = True,\n","    use_stemmer = True\n",")\n","\n","print(f'ORIGINAL MODEL RESULTS :\\n{original_model_scores}')\n","print(f'INSTRUCT MODEL RESULTS :\\n{instruct_model_scores}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPUyhSN_Q9LW","executionInfo":{"status":"ok","timestamp":1728255042634,"user_tz":240,"elapsed":11081,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"73ca8b6c-49e2-405f-c337-9952b4063097"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["ORIGINAL MODEL RESULTS :\n","{'rouge1': 0.23322885043181377, 'rouge2': 0.07600361713497218, 'rougeL': 0.20114846015422058, 'rougeLsum': 0.2015983575552877}\n","INSTRUCT MODEL RESULTS :\n","{'rouge1': 0.4212788823794692, 'rouge2': 0.18008655721611452, 'rougeL': 0.33820027705838673, 'rougeLsum': 0.3383688277552966}\n"]}]},{"cell_type":"code","source":["improvement = ((np.array(list(instruct_model_scores.values())))-(np.array(list(original_model_scores.values()))))\n","\n","for key,value in zip(instruct_model_scores.keys(),improvement):\n","  print(f'{key} : {value*100:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nsS4FlZSRXY0","executionInfo":{"status":"ok","timestamp":1728255042634,"user_tz":240,"elapsed":3,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"ec2b49fd-0785-464b-9b43-e495aadd4261"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["rouge1 : 18.81%\n","rouge2 : 10.41%\n","rougeL : 13.71%\n","rougeLsum : 13.68%\n"]}]},{"cell_type":"code","source":["from peft import LoraConfig, get_peft_model, TaskType\n","\n","lora_config = LoraConfig(\n","    r = 32,\n","    lora_alpha = 32,\n","    target_modules=[\"q\",\"v\"],\n","    lora_dropout=0.05,\n","    bias = \"none\",\n","    task_type = TaskType.SEQ_2_SEQ_LM\n",")"],"metadata":{"id":"oI5rzuLhSYax","executionInfo":{"status":"ok","timestamp":1728255449341,"user_tz":240,"elapsed":177,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["peft_model = get_peft_model(original_model, lora_config)\n","print(print_number_of_trainable_model_parameters(peft_model))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_DXZveoB45G","executionInfo":{"status":"ok","timestamp":1728255450369,"user_tz":240,"elapsed":158,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"24379b12-4c1f-4300-eca8-e064d8a97dc3"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable model parameters : 3538944\n","all model parameter : 251116800\n","percentage of trainable model parameters : 1.41%\n"]}]},{"cell_type":"code","source":["output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n","\n","peft_training_args = TrainingArguments(\n","    output_dir = output_dir,\n","    auto_find_batch_size = True,\n","    learning_rate = 1e-3,\n","    num_train_epochs = 1,\n","    logging_steps = 1,\n","    max_steps = 1\n",")\n","\n","peft_trainer = Trainer(model = peft_model,\n","                       args = peft_training_args,\n","                       train_dataset = tokenized_datasets[\"train\"])"],"metadata":{"id":"TOSwXHYZB7Wk","executionInfo":{"status":"ok","timestamp":1728256153470,"user_tz":240,"elapsed":346,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["%%time\n","peft_trainer.train()\n","\n","peft_model_path = \"./peft-dialogue-summary-checkpoint-local\"\n","\n","peft_trainer.model.save_pretrained(peft_model_path)\n","tokenizer.save_pretrained(peft_model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"OflvKm2pGBUx","executionInfo":{"status":"ok","timestamp":1728256730157,"user_tz":240,"elapsed":503742,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"701f008e-c167-4de7-d9bb-9fedd5de747d"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         )\n\u001b[0;32m-> 1633\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1634\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/memory.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No executable batch size found, reached zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_reduce_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2644\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2645\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2678\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, decoder_input_ids, decoder_attention_mask, decoder_inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m                 return self.base_model(\n\u001b[0m\u001b[1;32m   1860\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m             \u001b[0;31m# Convert encoder inputs in embeddings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1668\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1072\u001b[0m                 )\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1075\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["!aws s3 cp --recursive s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/ ./peft-dialogue-summary-checkpoint-from-s3/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_RMvLOLcGS_s","executionInfo":{"status":"ok","timestamp":1728256737332,"user_tz":240,"elapsed":2916,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"4f0a7e1c-f8a7-4c64-b26e-0678f9a7f8e0"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Completed 334 Bytes/15.9 MiB (370 Bytes/s) with 5 file(s) remaining\rdownload: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/adapter_config.json to peft-dialogue-summary-checkpoint-from-s3/adapter_config.json\n","Completed 334 Bytes/15.9 MiB (370 Bytes/s) with 4 file(s) remaining\rCompleted 2.5 KiB/15.9 MiB (2.6 KiB/s) with 4 file(s) remaining    \rdownload: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/special_tokens_map.json to peft-dialogue-summary-checkpoint-from-s3/special_tokens_map.json\n","Completed 2.5 KiB/15.9 MiB (2.6 KiB/s) with 3 file(s) remaining\rCompleted 4.9 KiB/15.9 MiB (5.1 KiB/s) with 3 file(s) remaining\rdownload: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/tokenizer_config.json to peft-dialogue-summary-checkpoint-from-s3/tokenizer_config.json\n","download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/tokenizer.json to peft-dialogue-summary-checkpoint-from-s3/tokenizer.json\n","download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/adapter_model.bin to peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin\n"]}]},{"cell_type":"code","source":["!ls -al ./peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ae34zlRxHAkm","executionInfo":{"status":"ok","timestamp":1728256737567,"user_tz":240,"elapsed":236,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"8dcb93fb-f5ee-4710-a6cb-7326c3c6afa5"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["-rw-r--r-- 1 root root 14208525 May 15  2023 ./peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin\n"]}]},{"cell_type":"code","source":["from peft import PeftModel, PeftConfig\n","\n","peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype = torch.bfloat16)\n","tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n","\n","peft_model = PeftModel.from_pretrained(peft_model_base,\n","                                       './peft-dialogue-summary-checkpoint-from-s3/',\n","                                       torch_dtype = torch.bfloat16,\n","                                       is_trainable = False)"],"metadata":{"id":"S-rTG57pHBwZ","executionInfo":{"status":"ok","timestamp":1728256748483,"user_tz":240,"elapsed":8808,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["print(print_number_of_trainable_model_parameters(peft_model))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KbrU6ABDH8Ob","executionInfo":{"status":"ok","timestamp":1728256748483,"user_tz":240,"elapsed":3,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"b41b8e25-970a-43d9-a0a3-5e74d3b94547"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable model parameters : 0\n","all model parameter : 251116800\n","percentage of trainable model parameters : 0.00%\n"]}]},{"cell_type":"code","source":["index = 200\n","\n","dialogue = dataset['test'][index]['dialogue']\n","summary = dataset['test'][index]['summary']\n","\n","prompt = f\"\"\"\n","Summarize the following conversation :\n","\n","{dialogue}\n","\n","Summary :\n","\"\"\"\n","\n","generate_config = GenerationConfig(max_new_tokens = 200, num_beams = 1)\n","input_ids = tokenizer(prompt, return_tensors = 'pt').input_ids\n","\n","original_model_output = tokenizer.decode(\n","                      original_model.generate(input_ids,\n","                                              generation_config = generate_config)[0],\n","                      skip_special_tokens = True\n",")\n","\n","instruct_model_output = tokenizer.decode(\n","                      instruct_model.generate(input_ids,\n","                                              generation_config = generate_config)[0],\n","                      skip_special_tokens = True\n",")\n","\n","peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n","peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n","\n","\n","dash_line = '-'.join('' for x in range(100))\n","print(dash_line)\n","print(f'INPUT PROMPT:\\n{prompt}')\n","print(dash_line)\n","print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n","print(dash_line)\n","print(f'ORIGINAL MODEL:\\n{original_model_output}\\n')\n","print(dash_line)\n","print(f'INSTRUCT MODEL:\\n{instruct_model_output}\\n')\n","print(dash_line)\n","print(f'PEFT MODEL:\\n{peft_model_text_output}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TitZINt5IDWt","executionInfo":{"status":"ok","timestamp":1728263021890,"user_tz":240,"elapsed":187,"user":{"displayName":"Pavan Pajjuri UB","userId":"17679281860940908394"}},"outputId":"e1242f49-1f2d-4d60-a513-7d5a3b06bf22"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------------------------\n","INPUT PROMPT:\n","\n","Summarize the following conversation :\n","\n","#Person1#: Have you considered upgrading your system?\n","#Person2#: Yes, but I'm not sure what exactly I would need.\n","#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n","#Person2#: That would be a definite bonus.\n","#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n","#Person2#: How can we do that?\n","#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n","#Person2#: No.\n","#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n","#Person2#: That sounds great. Thanks.\n","\n","Summary :\n","\n","---------------------------------------------------------------------------------------------------\n","BASELINE HUMAN SUMMARY:\n","#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n","---------------------------------------------------------------------------------------------------\n","ORIGINAL MODEL:\n","#Person1#: Have you considered upgrading your hardware?\n","\n","---------------------------------------------------------------------------------------------------\n","INSTRUCT MODEL:\n","#Person1# suggests #Person2# upgrading the system, hardware, and CD-ROM drive to make up for the outdated system. #Person2# thinks it sounds great.\n","\n","---------------------------------------------------------------------------------------------------\n","PEFT MODEL:\n","#Person1# recommends adding a painting program to #Person2#'s software and upgrading hardware. #Person2# also wants to upgrade the hardware because it's outdated now.\n","\n"]}]}]}